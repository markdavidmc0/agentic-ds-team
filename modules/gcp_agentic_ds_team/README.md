# README for GCP Agentic Data Science Team Terraform module

## Overview
This module provisions a GCP-based Agentic Data Science team infrastructure for the full lifecycle of fraud detection models, including:

- Raw and processed data storage in GCS buckets
- BigQuery dataset and table for feature storage
- Vertex AI Feature Store for managing features
- Cloud Run service for feature processing

## Features
- Agentic team with capabilities: data discovery, feature engineering, model training, evaluation, experiment tracking, and deployment
- GCS bucket for data and model artifacts
- Designed for fraud detection binary classification use cases
- Vertex AI for model training and endpoint deployment

## Usage
```hcl
module "gcp_agentic_ds_team" {
  source = "./modules/gcp_agentic_ds_team"

  organization_id      = "your-org-id"
  billing_account_id   = "your-billing-account-id"
  gcp_fraud_data_bucket_name = "fraud-raw-data"
  gcp_processed_data_bucket_name = "fraud-processed-data"
  gcp_location         = "europe-west2"
}
```

## Outputs
- `raw_data_bucket_name`: Name of the GCS bucket for raw data
- `processed_data_bucket_name`: Name of the GCS bucket for processed data
- `bigquery_dataset_id`: ID of the BigQuery dataset for fraud features

## Requirements
- Google Cloud project with BigQuery, Cloud Storage, and Vertex AI APIs enabled
- Terraform Google provider

## Limitations

**Note:** As of May 2025, Vertex AI model and endpoint deployment is not supported by the official Terraform Google provider. You must deploy models and endpoints using the gcloud CLI, Python SDK, or the GCP Console. This module provisions GCS and other supported infra only.

## Authors
- Generated by GitHub Copilot
