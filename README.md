# arch-to-iac
Text to Arch - Arch to Infrastructure as Code

## Overview
This repository provides infrastructure-as-code (IaC) for deploying an agentic Data Science team for fraud detection, supporting both AWS (Bedrock, SageMaker, S3) and GCP (Vertex AI, GCS). The architecture enables full DS lifecycle automation, from data discovery to model deployment, using modular Terraform code.

## Structure
- **AWS Deployment:**
  - `bedrock_agentic_ds_team.tf` (root module)
  - `modules/bedrock_agentic_ds_team/` (AWS-specific modules)
- **GCP Deployment:**
  - `gcp_agentic_ds_team.tf` (root module)
  - `modules/gcp_agentic_ds_team/` (GCP-specific modules)
- **Shared:**
  - `experiment_app.py` (Streamlit front end for experimentation prompt entry)
  - `data/` (fraud datasets in CSV/Parquet)
  - `generated-diagrams/` (architecture diagrams)

## How to Deploy

### AWS
1. Configure AWS credentials (least-privilege IAM user/role recommended).
2. Edit `bedrock_agentic_ds_team.tf` and variables as needed.
3. Run:
   ```zsh
   terraform init
   terraform apply
   ```

### GCP
1. Configure GCP credentials (least-privilege service account recommended).
2. Edit `gcp_agentic_ds_team.tf` and variables as needed.
3. Run:
   ```zsh
   terraform init
   terraform apply
   ```

## Security Best Practices
- S3/GCS buckets are encrypted, versioned, and block public access.
- IAM roles use least privilege and session duration limits.
- SageMaker/Vertex AI endpoints support encryption and tagging.

## Experimentation Front End
- Use `experiment_app.py` with Streamlit to submit experiment instructions to the agentic DS team (update API URL as needed).

## Diagrams
- See `generated-diagrams/` for architecture visualizations.

## Authors
- Generated by GitHub Copilot
